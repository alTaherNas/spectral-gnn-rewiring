{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SOOR"
      ],
      "metadata": {
        "id": "LoYzct7iX0FX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and Imports"
      ],
      "metadata": {
        "id": "Ph7nWu_prHa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8LZDHfCIPqs",
        "outputId": "695ae9bd-2b06-43d4-e76e-e5379c1e5b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import linalg\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.utils import to_networkx, from_networkx\n",
        "\n",
        "import random\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Running on {device}')\n",
        "\n",
        "seeds = [42, 220, 123, 456, 789, 1011, 1699, 38994, 52139, 123456]\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "Tni3WTlnInf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8021713-8aaa-4143-ce29-645271ebb7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "D-jbgVQgrQIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Node classification model\n",
        "class GCNNode(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNNode, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch=None):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "WKpgvVltP2oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Utils"
      ],
      "metadata": {
        "id": "uDxvDRUKrTxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Classification Training"
      ],
      "metadata": {
        "id": "1DID1ZN-9y2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwypECpgIHok"
      },
      "outputs": [],
      "source": [
        "def train_evaluate_node(input_dim, hidden_dims, output_dim, data, seeds, lr=1e-2, weight_decay=5e-4, patience=10):\n",
        "    accuracies = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\nSeed: {seed}\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        model = GCNNode(input_dim, hidden_dims, output_dim).to(device)\n",
        "        criterion = nn.NLLLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(300):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            data = data.to(device)\n",
        "            out = model(data.x, data.edge_index)\n",
        "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"  Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"  Epoch: {epoch+1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        data = data.to(device)\n",
        "        _, pred = model(data.x, data.edge_index).max(dim=1)\n",
        "        correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "        acc = correct / int(data.test_mask.sum())\n",
        "\n",
        "        accuracies.append(acc)\n",
        "        print(f\"  Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    variance_accuracy = np.var(accuracies)\n",
        "\n",
        "    print(f\"\\nAverage Accuracy: {avg_accuracy:.4f}\")\n",
        "    print(f\"Variance of Accuracy: {variance_accuracy:.4f}\")\n",
        "\n",
        "    return accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rewiring Algorithm"
      ],
      "metadata": {
        "id": "ue-tuMYgrqIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic idea is to use the curvature inequality in \"Revisiting Over-smoothing and Over-squashing Using Ollivier-Ricci Curvature\" without actually calculating the curvature.\n",
        "$$\\frac{|\\mathcal{N}_u \\cap \\mathcal{N}_v|}{\\max(m, n)} \\geq \\kappa(u, v)$$"
      ],
      "metadata": {
        "id": "lWNpbsyxOAo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_edges_with_spectral_smoothing(data, num_edges_to_remove, k=1):\n",
        "    G = to_networkx(data, to_undirected=True)\n",
        "    num_edges_before = G.number_of_edges()\n",
        "\n",
        "    # Compute the Laplacian matrix\n",
        "    L = nx.laplacian_matrix(G).toarray()\n",
        "\n",
        "    # Compute the eigenvalues and eigenvectors of the Laplacian matrix\n",
        "    eigenvalues, eigenvectors = linalg.eigh(L)\n",
        "\n",
        "    # Sort the eigenvalues and eigenvectors in ascending order\n",
        "    sorted_indices = np.argsort(eigenvalues)\n",
        "    eigenvalues = eigenvalues[sorted_indices]\n",
        "    eigenvectors = eigenvectors[:, sorted_indices]\n",
        "\n",
        "    # Select the eigenvectors corresponding to the k smallest eigenvalues\n",
        "    smoothest_eigenvectors = eigenvectors[:, 1:k+1]  # Exclude the first eigenvector\n",
        "\n",
        "    # Compute the contribution of each edge to the smoothest eigenvectors\n",
        "    edge_scores = {}\n",
        "    for u, v in G.edges():\n",
        "        edge_scores[(u, v)] = np.sum((smoothest_eigenvectors[u] - smoothest_eigenvectors[v])**2)\n",
        "\n",
        "    # Sort the edges based on their scores in ascending order\n",
        "    sorted_edges = sorted(edge_scores.items(), key=lambda x: x[1])\n",
        "\n",
        "    # Remove the edges with the lowest scores\n",
        "    edges_to_remove = [edge for edge, score in sorted_edges[:num_edges_to_remove]]\n",
        "    G.remove_edges_from(edges_to_remove)\n",
        "\n",
        "    num_edges_after = G.number_of_edges()\n",
        "    rewired_data = from_networkx(G)\n",
        "\n",
        "    # Clone the original data object\n",
        "    data_rewired = data.clone()\n",
        "    data_rewired.edge_index = rewired_data.edge_index\n",
        "\n",
        "    print(f\"Number of edges removed: {num_edges_before - num_edges_after}\")\n",
        "    return data_rewired"
      ],
      "metadata": {
        "id": "_bx3Bq5KrtoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "vgG-q4XZruJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cora"
      ],
      "metadata": {
        "id": "Wgm7TmX7r_SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "patience = 10\n",
        "\n",
        "# Load the Cora dataset\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora')\n",
        "data = dataset[0]\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "num_edges_before = G.number_of_edges()\n",
        "\n",
        "# Get the model dimensions\n",
        "input_dim = dataset.num_node_features\n",
        "hidden_dims = 16\n",
        "output_dim = dataset.num_classes\n",
        "\n",
        "# Train and evaluate the baseline model\n",
        "accuracies_baseline = train_evaluate_node(input_dim, hidden_dims, output_dim, data, seeds=seeds, patience=patience)\n",
        "baseline_accuracy = np.mean(accuracies_baseline)\n",
        "print(f\"Baseline Accuracy: {baseline_accuracy:.2%}\")\n",
        "\n",
        "accuracies_rewired_list = []\n",
        "p_values = []\n",
        "\n",
        "total_points = 50\n",
        "max_edges = int(num_edges_before * 0.02)\n",
        "step_size = max_edges // (total_points - 1) # Calculate the step size to evenly distribute the points\n",
        "edge_range = range(0, max_edges + 1, step_size)\n",
        "\n",
        "best_accuracy = baseline_accuracy\n",
        "best_edges_removed = 0\n",
        "best_p_value = 1.0\n",
        "\n",
        "start_time = time.time()\n",
        "for n_edges in edge_range:\n",
        "    # Apply rewiring algorithm\n",
        "    rewired_data = remove_edges_with_spectral_smoothing(data, n_edges)\n",
        "\n",
        "    # Train and evaluate the model on rewired data\n",
        "    accuracies_rewired = train_evaluate_node(input_dim, hidden_dims, output_dim, rewired_data, seeds=seeds, patience=patience)\n",
        "    rewired_accuracy = np.mean(accuracies_rewired)\n",
        "    accuracies_rewired_list.append(rewired_accuracy)\n",
        "\n",
        "    # Calculate percentage improvement\n",
        "    percentage_improvement = (rewired_accuracy - baseline_accuracy) * 100\n",
        "\n",
        "    # Perform statistical test\n",
        "    _, p_value = stats.ttest_rel(accuracies_rewired, accuracies_baseline)\n",
        "    p_values.append(p_value)\n",
        "\n",
        "    print(f\"Number of removed edges: {n_edges}, Rewired Accuracy: {rewired_accuracy:.2%}, \"\n",
        "          f\"Percentage Improvement: {percentage_improvement:.2f}%, P-value: {p_value:.4f}\")\n",
        "\n",
        "    # Update best hyperparameter if current accuracy is higher\n",
        "    if rewired_accuracy > best_accuracy:\n",
        "        best_accuracy = rewired_accuracy\n",
        "        best_edges_removed = n_edges\n",
        "        best_p_value = p_value\n",
        "\n",
        "print(\"\\n**********\")\n",
        "elapsed_time = time.time() - start_time\n",
        "minute, second = divmod(elapsed_time, 60)\n",
        "print(f\"Best Hyperparameter:\")\n",
        "print(f\"Number of removed edges: {best_edges_removed}\")\n",
        "print(f\"Accuracy: {best_accuracy:.2%}\")\n",
        "print(f\"Improvement: {best_accuracy - baseline_accuracy:.2%}\")\n",
        "print(f\"P-value: {best_p_value:.4f}\")\n",
        "print(\"**********\")\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(edge_range, [acc * 100 for acc in accuracies_rewired_list], marker='o', label='Rewired')\n",
        "plt.axhline(baseline_accuracy * 100, color='r', linestyle='--', label='Baseline')\n",
        "plt.xlabel('Number of Removed Edges')\n",
        "plt.ylabel('Test Accuracy (%)')\n",
        "plt.title('Test Accuracy vs. Edge Removal')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig('TestAccuracy_vs_EdgeRemoval.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jSvU6_Nprvi-",
        "outputId": "134a1118-72be-4499-fcd4-264ebdaf9904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8669, Val Loss: 1.3184\n",
            "  Epoch: 20, Train Loss: 0.2777, Val Loss: 0.9297\n",
            "  Epoch: 30, Train Loss: 0.1487, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9167\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7870\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8839, Val Loss: 1.2944\n",
            "  Epoch: 20, Train Loss: 0.2839, Val Loss: 0.9618\n",
            "  Epoch: 30, Train Loss: 0.0817, Val Loss: 0.9310\n",
            "  Epoch: 40, Train Loss: 0.0570, Val Loss: 0.8791\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8120\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7564, Val Loss: 1.2368\n",
            "  Epoch: 20, Train Loss: 0.2484, Val Loss: 0.9405\n",
            "  Epoch: 30, Train Loss: 0.1003, Val Loss: 0.9429\n",
            "  Epoch: 40, Train Loss: 0.0591, Val Loss: 0.9113\n",
            "  Epoch: 50, Train Loss: 0.0585, Val Loss: 0.9592\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8678, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2829, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1246, Val Loss: 0.9665\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7780\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8155, Val Loss: 1.3262\n",
            "  Epoch: 20, Train Loss: 0.2727, Val Loss: 0.9474\n",
            "  Epoch: 30, Train Loss: 0.0991, Val Loss: 0.9325\n",
            "  Epoch: 40, Train Loss: 0.0699, Val Loss: 1.0237\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8905, Val Loss: 1.3635\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9341\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9277\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7642, Val Loss: 1.2423\n",
            "  Epoch: 20, Train Loss: 0.2090, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1153, Val Loss: 0.8485\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8888, Val Loss: 1.4185\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.8575\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7880\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9575, Val Loss: 1.5001\n",
            "  Epoch: 20, Train Loss: 0.3196, Val Loss: 1.0540\n",
            "  Epoch: 30, Train Loss: 0.1198, Val Loss: 1.0242\n",
            "  Epoch: 40, Train Loss: 0.0836, Val Loss: 1.0690\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9282, Val Loss: 1.3224\n",
            "  Epoch: 20, Train Loss: 0.2936, Val Loss: 0.9793\n",
            "  Epoch: 30, Train Loss: 0.1114, Val Loss: 0.9119\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Average Accuracy: 0.7912\n",
            "Variance of Accuracy: 0.0002\n",
            "Baseline Accuracy: 79.12%\n",
            "Number of edges removed: 0\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8669, Val Loss: 1.3184\n",
            "  Epoch: 20, Train Loss: 0.2777, Val Loss: 0.9297\n",
            "  Epoch: 30, Train Loss: 0.1487, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9167\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7870\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8839, Val Loss: 1.2944\n",
            "  Epoch: 20, Train Loss: 0.2839, Val Loss: 0.9618\n",
            "  Epoch: 30, Train Loss: 0.0817, Val Loss: 0.9310\n",
            "  Epoch: 40, Train Loss: 0.0570, Val Loss: 0.8791\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8120\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7564, Val Loss: 1.2368\n",
            "  Epoch: 20, Train Loss: 0.2484, Val Loss: 0.9405\n",
            "  Epoch: 30, Train Loss: 0.1003, Val Loss: 0.9429\n",
            "  Epoch: 40, Train Loss: 0.0591, Val Loss: 0.9113\n",
            "  Epoch: 50, Train Loss: 0.0585, Val Loss: 0.9592\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8678, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2829, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1246, Val Loss: 0.9665\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7780\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8155, Val Loss: 1.3262\n",
            "  Epoch: 20, Train Loss: 0.2727, Val Loss: 0.9474\n",
            "  Epoch: 30, Train Loss: 0.0991, Val Loss: 0.9325\n",
            "  Epoch: 40, Train Loss: 0.0699, Val Loss: 1.0237\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8905, Val Loss: 1.3635\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9341\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9277\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7642, Val Loss: 1.2423\n",
            "  Epoch: 20, Train Loss: 0.2090, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1153, Val Loss: 0.8485\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8888, Val Loss: 1.4185\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.8575\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7880\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9575, Val Loss: 1.5001\n",
            "  Epoch: 20, Train Loss: 0.3196, Val Loss: 1.0540\n",
            "  Epoch: 30, Train Loss: 0.1198, Val Loss: 1.0242\n",
            "  Epoch: 40, Train Loss: 0.0836, Val Loss: 1.0690\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9282, Val Loss: 1.3224\n",
            "  Epoch: 20, Train Loss: 0.2936, Val Loss: 0.9793\n",
            "  Epoch: 30, Train Loss: 0.1114, Val Loss: 0.9119\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Average Accuracy: 0.7912\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 0, Rewired Accuracy: 79.12%, Percentage Improvement: 0.00%, P-value: nan\n",
            "Number of edges removed: 2\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7880\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8110\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7790\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Average Accuracy: 0.7917\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 2, Rewired Accuracy: 79.17%, Percentage Improvement: 0.05%, P-value: 0.3434\n",
            "Number of edges removed: 4\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7880\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8110\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7790\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Average Accuracy: 0.7917\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 4, Rewired Accuracy: 79.17%, Percentage Improvement: 0.05%, P-value: 0.3434\n",
            "Number of edges removed: 6\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7880\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8110\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7790\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Average Accuracy: 0.7917\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 6, Rewired Accuracy: 79.17%, Percentage Improvement: 0.05%, P-value: 0.3434\n",
            "Number of edges removed: 8\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8120\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7800\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Average Accuracy: 0.7924\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 8, Rewired Accuracy: 79.24%, Percentage Improvement: 0.12%, P-value: 0.0584\n",
            "Number of edges removed: 10\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8120\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7800\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Average Accuracy: 0.7924\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 10, Rewired Accuracy: 79.24%, Percentage Improvement: 0.12%, P-value: 0.0584\n",
            "Number of edges removed: 12\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8120\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7810\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Average Accuracy: 0.7924\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 12, Rewired Accuracy: 79.24%, Percentage Improvement: 0.12%, P-value: 0.0438\n",
            "Number of edges removed: 14\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8140\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Average Accuracy: 0.7939\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 14, Rewired Accuracy: 79.39%, Percentage Improvement: 0.27%, P-value: 0.0009\n",
            "Number of edges removed: 16\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8010\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Average Accuracy: 0.7944\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 16, Rewired Accuracy: 79.44%, Percentage Improvement: 0.32%, P-value: 0.0003\n",
            "Number of edges removed: 18\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8010\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Average Accuracy: 0.7942\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 18, Rewired Accuracy: 79.42%, Percentage Improvement: 0.30%, P-value: 0.0007\n",
            "Number of edges removed: 20\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8702, Val Loss: 1.3172\n",
            "  Epoch: 20, Train Loss: 0.2781, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9010\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9158\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8851, Val Loss: 1.2954\n",
            "  Epoch: 20, Train Loss: 0.2843, Val Loss: 0.9625\n",
            "  Epoch: 30, Train Loss: 0.0828, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0576, Val Loss: 0.8779\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2372\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9399\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2850, Val Loss: 0.9372\n",
            "  Epoch: 30, Train Loss: 0.1254, Val Loss: 0.9649\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8175, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0702, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1229, Val Loss: 0.9283\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7644, Val Loss: 1.2411\n",
            "  Epoch: 20, Train Loss: 0.2086, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8010\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8901, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2568, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9606, Val Loss: 1.5018\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0552\n",
            "  Epoch: 30, Train Loss: 0.1201, Val Loss: 1.0228\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0700\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2945, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9113\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Average Accuracy: 0.7942\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 20, Rewired Accuracy: 79.42%, Percentage Improvement: 0.30%, P-value: 0.0007\n",
            "Number of edges removed: 22\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3164\n",
            "  Epoch: 20, Train Loss: 0.2782, Val Loss: 0.9287\n",
            "  Epoch: 30, Train Loss: 0.1491, Val Loss: 0.9012\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9159\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8850, Val Loss: 1.2953\n",
            "  Epoch: 20, Train Loss: 0.2841, Val Loss: 0.9629\n",
            "  Epoch: 30, Train Loss: 0.0827, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0574, Val Loss: 0.8785\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7575, Val Loss: 1.2369\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9403\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9565\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2851, Val Loss: 0.9370\n",
            "  Epoch: 30, Train Loss: 0.1255, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8172, Val Loss: 1.3274\n",
            "  Epoch: 20, Train Loss: 0.2736, Val Loss: 0.9466\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9316\n",
            "  Epoch: 40, Train Loss: 0.0703, Val Loss: 1.0223\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8917, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1228, Val Loss: 0.9287\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7643, Val Loss: 1.2412\n",
            "  Epoch: 20, Train Loss: 0.2085, Val Loss: 0.8934\n",
            "  Epoch: 30, Train Loss: 0.1164, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8010\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4190\n",
            "  Epoch: 20, Train Loss: 0.2569, Val Loss: 0.8585\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9605, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0553\n",
            "  Epoch: 30, Train Loss: 0.1200, Val Loss: 1.0227\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3211\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7944\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 22, Rewired Accuracy: 79.44%, Percentage Improvement: 0.32%, P-value: 0.0002\n",
            "Number of edges removed: 24\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3164\n",
            "  Epoch: 20, Train Loss: 0.2782, Val Loss: 0.9287\n",
            "  Epoch: 30, Train Loss: 0.1491, Val Loss: 0.9012\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9159\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8850, Val Loss: 1.2953\n",
            "  Epoch: 20, Train Loss: 0.2841, Val Loss: 0.9629\n",
            "  Epoch: 30, Train Loss: 0.0827, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0574, Val Loss: 0.8785\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7575, Val Loss: 1.2369\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9403\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9565\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2851, Val Loss: 0.9370\n",
            "  Epoch: 30, Train Loss: 0.1255, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8172, Val Loss: 1.3274\n",
            "  Epoch: 20, Train Loss: 0.2736, Val Loss: 0.9466\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9316\n",
            "  Epoch: 40, Train Loss: 0.0703, Val Loss: 1.0223\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8917, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1228, Val Loss: 0.9287\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7643, Val Loss: 1.2412\n",
            "  Epoch: 20, Train Loss: 0.2085, Val Loss: 0.8934\n",
            "  Epoch: 30, Train Loss: 0.1164, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8010\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4190\n",
            "  Epoch: 20, Train Loss: 0.2569, Val Loss: 0.8585\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9605, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0553\n",
            "  Epoch: 30, Train Loss: 0.1200, Val Loss: 1.0227\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3211\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7944\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 24, Rewired Accuracy: 79.44%, Percentage Improvement: 0.32%, P-value: 0.0002\n",
            "Number of edges removed: 26\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3164\n",
            "  Epoch: 20, Train Loss: 0.2782, Val Loss: 0.9287\n",
            "  Epoch: 30, Train Loss: 0.1491, Val Loss: 0.9012\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9159\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8850, Val Loss: 1.2953\n",
            "  Epoch: 20, Train Loss: 0.2841, Val Loss: 0.9629\n",
            "  Epoch: 30, Train Loss: 0.0827, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0574, Val Loss: 0.8785\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7575, Val Loss: 1.2369\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9403\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9565\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2851, Val Loss: 0.9370\n",
            "  Epoch: 30, Train Loss: 0.1255, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8172, Val Loss: 1.3274\n",
            "  Epoch: 20, Train Loss: 0.2736, Val Loss: 0.9466\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9316\n",
            "  Epoch: 40, Train Loss: 0.0703, Val Loss: 1.0223\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8917, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1228, Val Loss: 0.9287\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7643, Val Loss: 1.2412\n",
            "  Epoch: 20, Train Loss: 0.2085, Val Loss: 0.8934\n",
            "  Epoch: 30, Train Loss: 0.1164, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4190\n",
            "  Epoch: 20, Train Loss: 0.2569, Val Loss: 0.8585\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9605, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0553\n",
            "  Epoch: 30, Train Loss: 0.1200, Val Loss: 1.0227\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3211\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7937\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 26, Rewired Accuracy: 79.37%, Percentage Improvement: 0.25%, P-value: 0.0007\n",
            "Number of edges removed: 28\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3164\n",
            "  Epoch: 20, Train Loss: 0.2782, Val Loss: 0.9287\n",
            "  Epoch: 30, Train Loss: 0.1491, Val Loss: 0.9012\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9159\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8850, Val Loss: 1.2953\n",
            "  Epoch: 20, Train Loss: 0.2841, Val Loss: 0.9629\n",
            "  Epoch: 30, Train Loss: 0.0827, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0574, Val Loss: 0.8785\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7575, Val Loss: 1.2369\n",
            "  Epoch: 20, Train Loss: 0.2485, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9403\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9102\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9565\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8736, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2851, Val Loss: 0.9370\n",
            "  Epoch: 30, Train Loss: 0.1255, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8172, Val Loss: 1.3274\n",
            "  Epoch: 20, Train Loss: 0.2736, Val Loss: 0.9466\n",
            "  Epoch: 30, Train Loss: 0.0996, Val Loss: 0.9316\n",
            "  Epoch: 40, Train Loss: 0.0703, Val Loss: 1.0223\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8917, Val Loss: 1.3642\n",
            "  Epoch: 20, Train Loss: 0.2304, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1228, Val Loss: 0.9287\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7643, Val Loss: 1.2412\n",
            "  Epoch: 20, Train Loss: 0.2085, Val Loss: 0.8934\n",
            "  Epoch: 30, Train Loss: 0.1164, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4190\n",
            "  Epoch: 20, Train Loss: 0.2569, Val Loss: 0.8585\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9605, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3239, Val Loss: 1.0553\n",
            "  Epoch: 30, Train Loss: 0.1200, Val Loss: 1.0227\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3211\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9778\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7937\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 28, Rewired Accuracy: 79.37%, Percentage Improvement: 0.25%, P-value: 0.0007\n",
            "Number of edges removed: 30\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3164\n",
            "  Epoch: 20, Train Loss: 0.2777, Val Loss: 0.9284\n",
            "  Epoch: 30, Train Loss: 0.1491, Val Loss: 0.9011\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8835, Val Loss: 1.2944\n",
            "  Epoch: 20, Train Loss: 0.2823, Val Loss: 0.9620\n",
            "  Epoch: 30, Train Loss: 0.0825, Val Loss: 0.9318\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8773\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8160\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7576, Val Loss: 1.2373\n",
            "  Epoch: 20, Train Loss: 0.2484, Val Loss: 0.9396\n",
            "  Epoch: 30, Train Loss: 0.1003, Val Loss: 0.9401\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9098\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9566\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8732, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2848, Val Loss: 0.9367\n",
            "  Epoch: 30, Train Loss: 0.1252, Val Loss: 0.9653\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3289\n",
            "  Epoch: 20, Train Loss: 0.2738, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0994, Val Loss: 0.9315\n",
            "  Epoch: 40, Train Loss: 0.0701, Val Loss: 1.0230\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8922, Val Loss: 1.3644\n",
            "  Epoch: 20, Train Loss: 0.2305, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1224, Val Loss: 0.9276\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7634, Val Loss: 1.2410\n",
            "  Epoch: 20, Train Loss: 0.2081, Val Loss: 0.8934\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8467\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8010\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8906, Val Loss: 1.4193\n",
            "  Epoch: 20, Train Loss: 0.2564, Val Loss: 0.8587\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9601, Val Loss: 1.5016\n",
            "  Epoch: 20, Train Loss: 0.3233, Val Loss: 1.0555\n",
            "  Epoch: 30, Train Loss: 0.1198, Val Loss: 1.0227\n",
            "  Epoch: 40, Train Loss: 0.0834, Val Loss: 1.0706\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7590\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9281, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2943, Val Loss: 0.9777\n",
            "  Epoch: 30, Train Loss: 0.1187, Val Loss: 0.9108\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Average Accuracy: 0.7936\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 30, Rewired Accuracy: 79.36%, Percentage Improvement: 0.24%, P-value: 0.0026\n",
            "Number of edges removed: 32\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3166\n",
            "  Epoch: 20, Train Loss: 0.2775, Val Loss: 0.9287\n",
            "  Epoch: 30, Train Loss: 0.1491, Val Loss: 0.9017\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9164\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8834, Val Loss: 1.2945\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9617\n",
            "  Epoch: 30, Train Loss: 0.0824, Val Loss: 0.9320\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8777\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7591, Val Loss: 1.2381\n",
            "  Epoch: 20, Train Loss: 0.2488, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1006, Val Loss: 0.9401\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9098\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9563\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8727, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2846, Val Loss: 0.9368\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9657\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8178, Val Loss: 1.3290\n",
            "  Epoch: 20, Train Loss: 0.2735, Val Loss: 0.9472\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0699, Val Loss: 1.0232\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8914, Val Loss: 1.3640\n",
            "  Epoch: 20, Train Loss: 0.2298, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1222, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7631, Val Loss: 1.2410\n",
            "  Epoch: 20, Train Loss: 0.2078, Val Loss: 0.8936\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8462\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8903, Val Loss: 1.4195\n",
            "  Epoch: 20, Train Loss: 0.2565, Val Loss: 0.8589\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9600, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3230, Val Loss: 1.0553\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0701\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7590\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9277, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2938, Val Loss: 0.9770\n",
            "  Epoch: 30, Train Loss: 0.1186, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7934\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 32, Rewired Accuracy: 79.34%, Percentage Improvement: 0.22%, P-value: 0.0026\n",
            "Number of edges removed: 34\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3166\n",
            "  Epoch: 20, Train Loss: 0.2775, Val Loss: 0.9287\n",
            "  Epoch: 30, Train Loss: 0.1491, Val Loss: 0.9017\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9164\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8834, Val Loss: 1.2945\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9617\n",
            "  Epoch: 30, Train Loss: 0.0824, Val Loss: 0.9320\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8777\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7591, Val Loss: 1.2381\n",
            "  Epoch: 20, Train Loss: 0.2488, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1006, Val Loss: 0.9401\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9098\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 0.9563\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8727, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2846, Val Loss: 0.9368\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9657\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8178, Val Loss: 1.3290\n",
            "  Epoch: 20, Train Loss: 0.2735, Val Loss: 0.9472\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0699, Val Loss: 1.0232\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8914, Val Loss: 1.3640\n",
            "  Epoch: 20, Train Loss: 0.2298, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1222, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7631, Val Loss: 1.2410\n",
            "  Epoch: 20, Train Loss: 0.2078, Val Loss: 0.8936\n",
            "  Epoch: 30, Train Loss: 0.1165, Val Loss: 0.8462\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8903, Val Loss: 1.4195\n",
            "  Epoch: 20, Train Loss: 0.2565, Val Loss: 0.8589\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9600, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3230, Val Loss: 1.0553\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0701\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7590\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9277, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2938, Val Loss: 0.9770\n",
            "  Epoch: 30, Train Loss: 0.1186, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7935\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 34, Rewired Accuracy: 79.35%, Percentage Improvement: 0.23%, P-value: 0.0026\n",
            "Number of edges removed: 36\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2775, Val Loss: 0.9290\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9163\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8832, Val Loss: 1.2945\n",
            "  Epoch: 20, Train Loss: 0.2819, Val Loss: 0.9620\n",
            "  Epoch: 30, Train Loss: 0.0824, Val Loss: 0.9319\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8773\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7591, Val Loss: 1.2381\n",
            "  Epoch: 20, Train Loss: 0.2489, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9398\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9096\n",
            "  Epoch: 50, Train Loss: 0.0585, Val Loss: 0.9561\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8728, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2846, Val Loss: 0.9368\n",
            "  Epoch: 30, Train Loss: 0.1250, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8178, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2735, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0992, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8919, Val Loss: 1.3644\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9356\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9276\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7627, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4194\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8587\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3229, Val Loss: 1.0550\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0225\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0696\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9288, Val Loss: 1.3215\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9775\n",
            "  Epoch: 30, Train Loss: 0.1184, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7937\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 36, Rewired Accuracy: 79.37%, Percentage Improvement: 0.25%, P-value: 0.0004\n",
            "Number of edges removed: 38\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2775, Val Loss: 0.9290\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9163\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8832, Val Loss: 1.2945\n",
            "  Epoch: 20, Train Loss: 0.2819, Val Loss: 0.9620\n",
            "  Epoch: 30, Train Loss: 0.0824, Val Loss: 0.9319\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8773\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7591, Val Loss: 1.2381\n",
            "  Epoch: 20, Train Loss: 0.2489, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9398\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9096\n",
            "  Epoch: 50, Train Loss: 0.0585, Val Loss: 0.9561\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8728, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2846, Val Loss: 0.9368\n",
            "  Epoch: 30, Train Loss: 0.1250, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8178, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2735, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0992, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8919, Val Loss: 1.3644\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9356\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9276\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7627, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4194\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8587\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3229, Val Loss: 1.0550\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0225\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0696\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9288, Val Loss: 1.3215\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9775\n",
            "  Epoch: 30, Train Loss: 0.1184, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7937\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 38, Rewired Accuracy: 79.37%, Percentage Improvement: 0.25%, P-value: 0.0004\n",
            "Number of edges removed: 40\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2775, Val Loss: 0.9290\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9163\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8832, Val Loss: 1.2945\n",
            "  Epoch: 20, Train Loss: 0.2819, Val Loss: 0.9620\n",
            "  Epoch: 30, Train Loss: 0.0824, Val Loss: 0.9319\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8773\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7591, Val Loss: 1.2381\n",
            "  Epoch: 20, Train Loss: 0.2489, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9398\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9096\n",
            "  Epoch: 50, Train Loss: 0.0585, Val Loss: 0.9561\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8728, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2846, Val Loss: 0.9368\n",
            "  Epoch: 30, Train Loss: 0.1250, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8178, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2735, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0992, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8919, Val Loss: 1.3644\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9356\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9276\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7627, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4194\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8587\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3229, Val Loss: 1.0550\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0225\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0696\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9288, Val Loss: 1.3215\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9775\n",
            "  Epoch: 30, Train Loss: 0.1184, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7937\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 40, Rewired Accuracy: 79.37%, Percentage Improvement: 0.25%, P-value: 0.0004\n",
            "Number of edges removed: 42\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2775, Val Loss: 0.9290\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9163\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8832, Val Loss: 1.2945\n",
            "  Epoch: 20, Train Loss: 0.2819, Val Loss: 0.9620\n",
            "  Epoch: 30, Train Loss: 0.0824, Val Loss: 0.9319\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8773\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7591, Val Loss: 1.2381\n",
            "  Epoch: 20, Train Loss: 0.2489, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9398\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9096\n",
            "  Epoch: 50, Train Loss: 0.0585, Val Loss: 0.9561\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8728, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2846, Val Loss: 0.9368\n",
            "  Epoch: 30, Train Loss: 0.1250, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8178, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2735, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0992, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8919, Val Loss: 1.3644\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9356\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9276\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7627, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4194\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8587\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3229, Val Loss: 1.0550\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0225\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0696\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9288, Val Loss: 1.3215\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9775\n",
            "  Epoch: 30, Train Loss: 0.1184, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7937\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 42, Rewired Accuracy: 79.37%, Percentage Improvement: 0.25%, P-value: 0.0004\n",
            "Number of edges removed: 44\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2775, Val Loss: 0.9290\n",
            "  Epoch: 30, Train Loss: 0.1490, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9163\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8832, Val Loss: 1.2945\n",
            "  Epoch: 20, Train Loss: 0.2819, Val Loss: 0.9620\n",
            "  Epoch: 30, Train Loss: 0.0824, Val Loss: 0.9319\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8773\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7591, Val Loss: 1.2381\n",
            "  Epoch: 20, Train Loss: 0.2489, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9398\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9096\n",
            "  Epoch: 50, Train Loss: 0.0585, Val Loss: 0.9561\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8050\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8728, Val Loss: 1.3656\n",
            "  Epoch: 20, Train Loss: 0.2846, Val Loss: 0.9368\n",
            "  Epoch: 30, Train Loss: 0.1250, Val Loss: 0.9654\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8178, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2735, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0992, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8919, Val Loss: 1.3644\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9356\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9276\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7627, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8933\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8463\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8902, Val Loss: 1.4194\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8587\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3229, Val Loss: 1.0550\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0225\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0696\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9288, Val Loss: 1.3215\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9775\n",
            "  Epoch: 30, Train Loss: 0.1184, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Average Accuracy: 0.7943\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 44, Rewired Accuracy: 79.43%, Percentage Improvement: 0.31%, P-value: 0.0004\n",
            "Number of edges removed: 46\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9619\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9317\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8772\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8150\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2380\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9397\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9088\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3653\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9362\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3643\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8467\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.8000\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4188\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8583\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0547\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7610\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3214\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9779\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Average Accuracy: 0.7939\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 46, Rewired Accuracy: 79.39%, Percentage Improvement: 0.27%, P-value: 0.0004\n",
            "Number of edges removed: 48\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7880\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9619\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9317\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8772\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8130\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2380\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9397\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9088\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3653\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9362\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7800\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7960\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3643\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8467\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7990\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4188\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8583\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0547\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7590\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3214\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9779\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Average Accuracy: 0.7924\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 48, Rewired Accuracy: 79.24%, Percentage Improvement: 0.12%, P-value: 0.0735\n",
            "Number of edges removed: 50\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9619\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9317\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8772\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8120\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2380\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9397\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9088\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8020\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3653\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9362\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7790\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3643\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8467\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4188\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8583\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0547\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7590\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3214\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9779\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Average Accuracy: 0.7908\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 50, Rewired Accuracy: 79.08%, Percentage Improvement: -0.04%, P-value: 0.5744\n",
            "Number of edges removed: 52\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7860\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9619\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9317\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8772\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2380\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9397\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9088\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3653\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9362\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7790\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3643\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8467\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4188\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8583\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0547\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3214\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9779\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Average Accuracy: 0.7907\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 52, Rewired Accuracy: 79.07%, Percentage Improvement: -0.05%, P-value: 0.5437\n",
            "Number of edges removed: 54\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7860\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9619\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9317\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8772\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8070\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2380\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9397\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9088\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3653\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9362\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7780\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3643\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8467\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4188\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8583\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7880\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0547\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7590\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3214\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9779\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Average Accuracy: 0.7897\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 54, Rewired Accuracy: 78.97%, Percentage Improvement: -0.15%, P-value: 0.1006\n",
            "Number of edges removed: 56\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7860\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9619\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9317\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8772\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8070\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2380\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9397\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9088\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3653\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9362\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7780\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3643\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8467\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7980\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4188\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8583\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7880\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0547\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7590\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3214\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9779\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Average Accuracy: 0.7897\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 56, Rewired Accuracy: 78.97%, Percentage Improvement: -0.15%, P-value: 0.1006\n",
            "Number of edges removed: 58\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9285\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9619\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9317\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8772\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8060\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2380\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9397\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9397\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9088\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3653\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9362\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9473\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3643\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9355\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9273\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8467\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4188\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8583\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5017\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0547\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0226\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0699\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3214\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9779\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9107\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7895\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 58, Rewired Accuracy: 78.95%, Percentage Improvement: -0.17%, P-value: 0.1013\n",
            "Number of edges removed: 60\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3169\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9291\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9023\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9160\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9611\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9319\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8774\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8060\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2384\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9399\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9404\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9101\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3654\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9358\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3290\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9472\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9322\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3644\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9275\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8935\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8472\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4192\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8587\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5020\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0539\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0225\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0698\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3212\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9782\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9112\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7894\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 60, Rewired Accuracy: 78.94%, Percentage Improvement: -0.18%, P-value: 0.0947\n",
            "Number of edges removed: 62\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9291\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9022\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9161\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2946\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9609\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9319\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8773\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8060\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2384\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9398\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9404\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9100\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9561\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3654\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9357\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9658\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3290\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9471\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0229\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3644\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9276\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2405\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8936\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8471\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4192\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8586\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5019\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0538\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0224\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0697\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3212\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9783\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9111\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7894\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 62, Rewired Accuracy: 78.94%, Percentage Improvement: -0.18%, P-value: 0.0947\n",
            "Number of edges removed: 64\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3168\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9289\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9021\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9157\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2944\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9610\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9317\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8775\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8060\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2384\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9402\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9407\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9103\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9562\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9362\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9666\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3287\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9470\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9321\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0228\n",
            "  Early stopping at epoch 41\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3645\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9351\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9276\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2404\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8936\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8472\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4191\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8588\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5020\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0538\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0222\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0701\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3209\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9782\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9110\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7894\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 64, Rewired Accuracy: 78.94%, Percentage Improvement: -0.18%, P-value: 0.0947\n",
            "Number of edges removed: 66\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3176\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9291\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9090\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9170\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2950\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9631\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9342\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8824\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8060\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2381\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9407\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9430\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9121\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9573\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3653\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9373\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9694\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3292\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9483\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9363\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0231\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3646\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9352\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9288\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2404\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8946\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8483\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4195\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8620\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5028\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0564\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0263\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0784\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9810\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9182\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7895\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 66, Rewired Accuracy: 78.95%, Percentage Improvement: -0.17%, P-value: 0.1051\n",
            "Number of edges removed: 68\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3178\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9295\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9078\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9190\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2944\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9644\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9361\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8911\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8060\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2385\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9486\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9481\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9143\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9589\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3668\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9403\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9695\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3292\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9472\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9414\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0264\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3659\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9384\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9305\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2437\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9000\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8490\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4195\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8639\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5032\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0564\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0274\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0803\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9827\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9205\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7895\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 68, Rewired Accuracy: 78.95%, Percentage Improvement: -0.17%, P-value: 0.1051\n",
            "Number of edges removed: 70\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3187\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9298\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9078\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9211\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2961\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9648\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9360\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8910\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8060\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2396\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9491\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9482\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9197\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9593\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3666\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9408\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9711\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3297\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9521\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9411\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0264\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9389\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9305\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2438\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8986\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8490\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4207\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8643\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5039\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0562\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0288\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0800\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3210\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9827\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9184\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7895\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 70, Rewired Accuracy: 78.95%, Percentage Improvement: -0.17%, P-value: 0.1051\n",
            "Number of edges removed: 72\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3195\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9339\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9129\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9213\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2958\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9642\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9465\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8869\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8050\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2400\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9477\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9495\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9176\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9582\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3682\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9427\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9754\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9531\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9421\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0222\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3659\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9375\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9284\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2444\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.8981\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8582\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4222\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8628\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5025\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0555\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0271\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0859\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3201\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9838\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9232\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7892\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 72, Rewired Accuracy: 78.92%, Percentage Improvement: -0.20%, P-value: 0.0656\n",
            "Number of edges removed: 74\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3207\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9382\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9141\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9347\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2978\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9620\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9469\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8915\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8050\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2374\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9485\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9494\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9161\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9582\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3688\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9529\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9738\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3291\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9653\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9427\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0188\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3658\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9418\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9318\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2469\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9023\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8594\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4209\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8626\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5033\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0574\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0268\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0864\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3195\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9850\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9225\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7892\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 74, Rewired Accuracy: 78.92%, Percentage Improvement: -0.20%, P-value: 0.0656\n",
            "Number of edges removed: 76\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3211\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9386\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9152\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9362\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.2983\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9612\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9468\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8926\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8050\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2364\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9487\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9495\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9142\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9582\n",
            "  Early stopping at epoch 52\n",
            "  Test Accuracy: 0.8030\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3685\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9536\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9738\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3298\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9659\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9426\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0189\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3655\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9426\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9318\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2483\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9029\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8602\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4202\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8624\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5029\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0586\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0271\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0869\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3192\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9859\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9232\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7892\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 76, Rewired Accuracy: 78.92%, Percentage Improvement: -0.20%, P-value: 0.0656\n",
            "Number of edges removed: 78\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3189\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9427\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9183\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9650\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3023\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9670\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9575\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8914\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8050\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2413\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9603\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9593\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9180\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9729\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.8916\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3685\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9623\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9839\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3304\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9657\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9601\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0181\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3639\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9453\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9358\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2551\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9077\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8720\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4217\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8691\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5037\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0615\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0270\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.0995\n",
            "  Early stopping at epoch 47\n",
            "  Test Accuracy: 0.7720\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3205\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9941\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9318\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7910\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 78, Rewired Accuracy: 79.10%, Percentage Improvement: -0.02%, P-value: 0.9170\n",
            "Number of edges removed: 80\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3205\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9456\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9198\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9697\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7840\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3024\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9681\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9593\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8923\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8050\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2437\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9601\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9618\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9239\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9754\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.8936\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3696\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9640\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9844\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3312\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9668\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9640\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0221\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3650\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9453\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9375\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2564\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9088\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8725\n",
            "  Early stopping at epoch 37\n",
            "  Test Accuracy: 0.7970\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4225\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8772\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5037\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0646\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0278\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1006\n",
            "  Early stopping at epoch 43\n",
            "  Test Accuracy: 0.7650\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3212\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9953\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9350\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7901\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 80, Rewired Accuracy: 79.01%, Percentage Improvement: -0.11%, P-value: 0.4906\n",
            "Number of edges removed: 82\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3227\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9514\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9242\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9743\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3041\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9686\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9593\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8941\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8050\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2453\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9630\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9714\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9264\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9847\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9008\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3732\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9751\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9903\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3312\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9691\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9686\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0340\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3645\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9484\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9419\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2613\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9179\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8746\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7950\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4234\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8791\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5062\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0729\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0323\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1079\n",
            "  Early stopping at epoch 43\n",
            "  Test Accuracy: 0.7650\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3224\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9984\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9424\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7901\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 82, Rewired Accuracy: 79.01%, Percentage Improvement: -0.11%, P-value: 0.4803\n",
            "Number of edges removed: 84\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3235\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9530\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9275\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9755\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3042\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9681\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9583\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8939\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2451\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9637\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9722\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9283\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9872\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9019\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8100\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3729\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9748\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9885\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3315\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9692\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9694\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0327\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3648\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9493\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9422\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2611\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9193\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8756\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4232\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8786\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5056\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0731\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0324\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1090\n",
            "  Early stopping at epoch 43\n",
            "  Test Accuracy: 0.7650\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3225\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 0.9982\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9407\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7900\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 84, Rewired Accuracy: 79.00%, Percentage Improvement: -0.12%, P-value: 0.4790\n",
            "Number of edges removed: 86\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3232\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9568\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9255\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9740\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3077\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9730\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9598\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8949\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2482\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9660\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9707\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9371\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9950\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9037\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8100\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3751\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9755\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9923\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3349\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9753\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9658\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0294\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3675\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9508\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9411\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2596\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9216\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8750\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4217\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8843\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5049\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0738\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0292\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1123\n",
            "  Early stopping at epoch 43\n",
            "  Test Accuracy: 0.7650\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3267\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 1.0026\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9464\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7900\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 86, Rewired Accuracy: 79.00%, Percentage Improvement: -0.12%, P-value: 0.4790\n",
            "Number of edges removed: 88\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3228\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9571\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9253\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9737\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3075\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9720\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9600\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8940\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2478\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9660\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9703\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9369\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 0.9947\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9038\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3752\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9756\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9921\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3348\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9754\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9653\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0298\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3678\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9505\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9414\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2596\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9218\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8750\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4216\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8847\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5050\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0745\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0291\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1141\n",
            "  Early stopping at epoch 43\n",
            "  Test Accuracy: 0.7650\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3269\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 1.0028\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9448\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7899\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 88, Rewired Accuracy: 78.99%, Percentage Improvement: -0.13%, P-value: 0.4232\n",
            "Number of edges removed: 90\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3234\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9575\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9353\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9815\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3096\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9766\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9672\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.8951\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2501\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9669\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9767\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9371\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 1.0029\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9066\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3748\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9762\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9933\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3360\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9786\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9657\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0335\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3688\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9603\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9457\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2577\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9284\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8774\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4249\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8864\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5050\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0729\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0349\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1159\n",
            "  Early stopping at epoch 47\n",
            "  Test Accuracy: 0.7720\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3273\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 1.0043\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9462\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7906\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 90, Rewired Accuracy: 79.06%, Percentage Improvement: -0.06%, P-value: 0.7627\n",
            "Number of edges removed: 92\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3245\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9602\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9420\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9864\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3110\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9784\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9693\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.9016\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2497\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9680\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9804\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9372\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 1.0084\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9081\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3738\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9801\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9930\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3373\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9807\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9683\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0360\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3700\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9608\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9466\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2579\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9304\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8835\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4243\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8844\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5042\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0764\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0384\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1217\n",
            "  Early stopping at epoch 47\n",
            "  Test Accuracy: 0.7720\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3265\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 1.0094\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9466\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7906\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 92, Rewired Accuracy: 79.06%, Percentage Improvement: -0.06%, P-value: 0.7627\n",
            "Number of edges removed: 94\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8697, Val Loss: 1.3248\n",
            "  Epoch: 20, Train Loss: 0.2773, Val Loss: 0.9612\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9424\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9858\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8830, Val Loss: 1.3113\n",
            "  Epoch: 20, Train Loss: 0.2818, Val Loss: 0.9787\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9685\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.9024\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7592, Val Loss: 1.2508\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9681\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9804\n",
            "  Epoch: 40, Train Loss: 0.0588, Val Loss: 0.9378\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 1.0084\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9082\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8725, Val Loss: 1.3745\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9802\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9941\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8177, Val Loss: 1.3368\n",
            "  Epoch: 20, Train Loss: 0.2734, Val Loss: 0.9810\n",
            "  Epoch: 30, Train Loss: 0.0993, Val Loss: 0.9681\n",
            "  Epoch: 40, Train Loss: 0.0700, Val Loss: 1.0384\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8918, Val Loss: 1.3700\n",
            "  Epoch: 20, Train Loss: 0.2300, Val Loss: 0.9617\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9486\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7625, Val Loss: 1.2585\n",
            "  Epoch: 20, Train Loss: 0.2077, Val Loss: 0.9309\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8847\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8899, Val Loss: 1.4246\n",
            "  Epoch: 20, Train Loss: 0.2562, Val Loss: 0.8858\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9599, Val Loss: 1.5042\n",
            "  Epoch: 20, Train Loss: 0.3227, Val Loss: 1.0766\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0390\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1230\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7600\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9287, Val Loss: 1.3274\n",
            "  Epoch: 20, Train Loss: 0.2944, Val Loss: 1.0107\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9473\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7894\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 94, Rewired Accuracy: 78.94%, Percentage Improvement: -0.18%, P-value: 0.2416\n",
            "Number of edges removed: 96\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3249\n",
            "  Epoch: 20, Train Loss: 0.2774, Val Loss: 0.9615\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9418\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9856\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8835, Val Loss: 1.3118\n",
            "  Epoch: 20, Train Loss: 0.2819, Val Loss: 0.9786\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9689\n",
            "  Epoch: 40, Train Loss: 0.0565, Val Loss: 0.9024\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7593, Val Loss: 1.2508\n",
            "  Epoch: 20, Train Loss: 0.2489, Val Loss: 0.9684\n",
            "  Epoch: 30, Train Loss: 0.1006, Val Loss: 0.9801\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9376\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 1.0078\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9081\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8724, Val Loss: 1.3750\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9816\n",
            "  Epoch: 30, Train Loss: 0.1248, Val Loss: 0.9937\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8171, Val Loss: 1.3366\n",
            "  Epoch: 20, Train Loss: 0.2732, Val Loss: 0.9811\n",
            "  Epoch: 30, Train Loss: 0.0990, Val Loss: 0.9678\n",
            "  Epoch: 40, Train Loss: 0.0699, Val Loss: 1.0379\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8922, Val Loss: 1.3702\n",
            "  Epoch: 20, Train Loss: 0.2302, Val Loss: 0.9624\n",
            "  Epoch: 30, Train Loss: 0.1224, Val Loss: 0.9493\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7615, Val Loss: 1.2588\n",
            "  Epoch: 20, Train Loss: 0.2080, Val Loss: 0.9313\n",
            "  Epoch: 30, Train Loss: 0.1164, Val Loss: 0.8844\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8896, Val Loss: 1.4242\n",
            "  Epoch: 20, Train Loss: 0.2559, Val Loss: 0.8864\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9590, Val Loss: 1.5042\n",
            "  Epoch: 20, Train Loss: 0.3229, Val Loss: 1.0762\n",
            "  Epoch: 30, Train Loss: 0.1195, Val Loss: 1.0395\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7660\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9286, Val Loss: 1.3277\n",
            "  Epoch: 20, Train Loss: 0.2941, Val Loss: 1.0108\n",
            "  Epoch: 30, Train Loss: 0.1186, Val Loss: 0.9484\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7920\n",
            "\n",
            "Average Accuracy: 0.7898\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 96, Rewired Accuracy: 78.98%, Percentage Improvement: -0.14%, P-value: 0.4157\n",
            "Number of edges removed: 98\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3240\n",
            "  Epoch: 20, Train Loss: 0.2774, Val Loss: 0.9602\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9423\n",
            "  Epoch: 40, Train Loss: 0.0664, Val Loss: 0.9854\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8835, Val Loss: 1.3109\n",
            "  Epoch: 20, Train Loss: 0.2819, Val Loss: 0.9755\n",
            "  Epoch: 30, Train Loss: 0.0823, Val Loss: 0.9668\n",
            "  Epoch: 40, Train Loss: 0.0565, Val Loss: 0.9003\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7593, Val Loss: 1.2498\n",
            "  Epoch: 20, Train Loss: 0.2489, Val Loss: 0.9679\n",
            "  Epoch: 30, Train Loss: 0.1006, Val Loss: 0.9789\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9352\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 1.0073\n",
            "  Epoch: 60, Train Loss: 0.0521, Val Loss: 0.9082\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8090\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8724, Val Loss: 1.3752\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9806\n",
            "  Epoch: 30, Train Loss: 0.1248, Val Loss: 0.9916\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8171, Val Loss: 1.3362\n",
            "  Epoch: 20, Train Loss: 0.2732, Val Loss: 0.9789\n",
            "  Epoch: 30, Train Loss: 0.0990, Val Loss: 0.9673\n",
            "  Epoch: 40, Train Loss: 0.0699, Val Loss: 1.0310\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8922, Val Loss: 1.3700\n",
            "  Epoch: 20, Train Loss: 0.2302, Val Loss: 0.9601\n",
            "  Epoch: 30, Train Loss: 0.1224, Val Loss: 0.9447\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7870\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7615, Val Loss: 1.2591\n",
            "  Epoch: 20, Train Loss: 0.2080, Val Loss: 0.9300\n",
            "  Epoch: 30, Train Loss: 0.1164, Val Loss: 0.8828\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8896, Val Loss: 1.4235\n",
            "  Epoch: 20, Train Loss: 0.2559, Val Loss: 0.8852\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9590, Val Loss: 1.5039\n",
            "  Epoch: 20, Train Loss: 0.3229, Val Loss: 1.0755\n",
            "  Epoch: 30, Train Loss: 0.1195, Val Loss: 1.0395\n",
            "  Epoch: 40, Train Loss: 0.0834, Val Loss: 1.1219\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7590\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9286, Val Loss: 1.3273\n",
            "  Epoch: 20, Train Loss: 0.2941, Val Loss: 1.0080\n",
            "  Epoch: 30, Train Loss: 0.1186, Val Loss: 0.9452\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Average Accuracy: 0.7888\n",
            "Variance of Accuracy: 0.0002\n",
            "Number of removed edges: 98, Rewired Accuracy: 78.88%, Percentage Improvement: -0.24%, P-value: 0.1595\n",
            "Number of edges removed: 100\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8698, Val Loss: 1.3247\n",
            "  Epoch: 20, Train Loss: 0.2775, Val Loss: 0.9624\n",
            "  Epoch: 30, Train Loss: 0.1493, Val Loss: 0.9440\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9851\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7850\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8839, Val Loss: 1.3116\n",
            "  Epoch: 20, Train Loss: 0.2823, Val Loss: 0.9746\n",
            "  Epoch: 30, Train Loss: 0.0825, Val Loss: 0.9676\n",
            "  Epoch: 40, Train Loss: 0.0567, Val Loss: 0.9001\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7594, Val Loss: 1.2490\n",
            "  Epoch: 20, Train Loss: 0.2491, Val Loss: 0.9688\n",
            "  Epoch: 30, Train Loss: 0.1006, Val Loss: 0.9804\n",
            "  Epoch: 40, Train Loss: 0.0589, Val Loss: 0.9370\n",
            "  Epoch: 50, Train Loss: 0.0586, Val Loss: 1.0086\n",
            "  Epoch: 60, Train Loss: 0.0520, Val Loss: 0.9106\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8070\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8718, Val Loss: 1.3744\n",
            "  Epoch: 20, Train Loss: 0.2846, Val Loss: 0.9832\n",
            "  Epoch: 30, Train Loss: 0.1249, Val Loss: 0.9974\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8166, Val Loss: 1.3360\n",
            "  Epoch: 20, Train Loss: 0.2727, Val Loss: 0.9815\n",
            "  Epoch: 30, Train Loss: 0.0988, Val Loss: 0.9684\n",
            "  Epoch: 40, Train Loss: 0.0696, Val Loss: 1.0278\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8922, Val Loss: 1.3699\n",
            "  Epoch: 20, Train Loss: 0.2301, Val Loss: 0.9600\n",
            "  Epoch: 30, Train Loss: 0.1224, Val Loss: 0.9448\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7870\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7615, Val Loss: 1.2580\n",
            "  Epoch: 20, Train Loss: 0.2075, Val Loss: 0.9260\n",
            "  Epoch: 30, Train Loss: 0.1163, Val Loss: 0.8931\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8895, Val Loss: 1.4235\n",
            "  Epoch: 20, Train Loss: 0.2558, Val Loss: 0.8853\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7900\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9591, Val Loss: 1.5048\n",
            "  Epoch: 20, Train Loss: 0.3231, Val Loss: 1.0769\n",
            "  Epoch: 30, Train Loss: 0.1196, Val Loss: 1.0421\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7650\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9251, Val Loss: 1.3262\n",
            "  Epoch: 20, Train Loss: 0.2932, Val Loss: 1.0128\n",
            "  Epoch: 30, Train Loss: 0.1184, Val Loss: 0.9489\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Average Accuracy: 0.7893\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 100, Rewired Accuracy: 78.93%, Percentage Improvement: -0.19%, P-value: 0.2601\n",
            "Number of edges removed: 102\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8698, Val Loss: 1.3254\n",
            "  Epoch: 20, Train Loss: 0.2778, Val Loss: 0.9626\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9442\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9854\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7860\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8820, Val Loss: 1.3111\n",
            "  Epoch: 20, Train Loss: 0.2817, Val Loss: 0.9757\n",
            "  Epoch: 30, Train Loss: 0.0822, Val Loss: 0.9682\n",
            "  Epoch: 40, Train Loss: 0.0565, Val Loss: 0.9016\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7585, Val Loss: 1.2482\n",
            "  Epoch: 20, Train Loss: 0.2490, Val Loss: 0.9689\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9813\n",
            "  Epoch: 40, Train Loss: 0.0591, Val Loss: 0.9380\n",
            "  Epoch: 50, Train Loss: 0.0587, Val Loss: 1.0093\n",
            "  Epoch: 60, Train Loss: 0.0520, Val Loss: 0.9107\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8070\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8728, Val Loss: 1.3742\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9825\n",
            "  Epoch: 30, Train Loss: 0.1248, Val Loss: 0.9973\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8166, Val Loss: 1.3367\n",
            "  Epoch: 20, Train Loss: 0.2731, Val Loss: 0.9833\n",
            "  Epoch: 30, Train Loss: 0.0985, Val Loss: 0.9680\n",
            "  Epoch: 40, Train Loss: 0.0698, Val Loss: 1.0296\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8928, Val Loss: 1.3698\n",
            "  Epoch: 20, Train Loss: 0.2301, Val Loss: 0.9601\n",
            "  Epoch: 30, Train Loss: 0.1224, Val Loss: 0.9456\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7870\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7629, Val Loss: 1.2585\n",
            "  Epoch: 20, Train Loss: 0.2081, Val Loss: 0.9265\n",
            "  Epoch: 30, Train Loss: 0.1161, Val Loss: 0.8926\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8895, Val Loss: 1.4234\n",
            "  Epoch: 20, Train Loss: 0.2556, Val Loss: 0.8858\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9593, Val Loss: 1.5040\n",
            "  Epoch: 20, Train Loss: 0.3226, Val Loss: 1.0761\n",
            "  Epoch: 30, Train Loss: 0.1197, Val Loss: 1.0406\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1250\n",
            "  Early stopping at epoch 47\n",
            "  Test Accuracy: 0.7730\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9234, Val Loss: 1.3253\n",
            "  Epoch: 20, Train Loss: 0.2929, Val Loss: 1.0128\n",
            "  Epoch: 30, Train Loss: 0.1184, Val Loss: 0.9480\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Average Accuracy: 0.7902\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 102, Rewired Accuracy: 79.02%, Percentage Improvement: -0.10%, P-value: 0.6309\n",
            "Number of edges removed: 104\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.8699, Val Loss: 1.3259\n",
            "  Epoch: 20, Train Loss: 0.2779, Val Loss: 0.9623\n",
            "  Epoch: 30, Train Loss: 0.1492, Val Loss: 0.9445\n",
            "  Epoch: 40, Train Loss: 0.0665, Val Loss: 0.9853\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.7840\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.8816, Val Loss: 1.3106\n",
            "  Epoch: 20, Train Loss: 0.2813, Val Loss: 0.9762\n",
            "  Epoch: 30, Train Loss: 0.0820, Val Loss: 0.9692\n",
            "  Epoch: 40, Train Loss: 0.0565, Val Loss: 0.9020\n",
            "  Early stopping at epoch 45\n",
            "  Test Accuracy: 0.8040\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.7584, Val Loss: 1.2488\n",
            "  Epoch: 20, Train Loss: 0.2491, Val Loss: 0.9685\n",
            "  Epoch: 30, Train Loss: 0.1005, Val Loss: 0.9820\n",
            "  Epoch: 40, Train Loss: 0.0591, Val Loss: 0.9392\n",
            "  Epoch: 50, Train Loss: 0.0588, Val Loss: 1.0087\n",
            "  Epoch: 60, Train Loss: 0.0519, Val Loss: 0.9115\n",
            "  Early stopping at epoch 60\n",
            "  Test Accuracy: 0.8070\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.8727, Val Loss: 1.3746\n",
            "  Epoch: 20, Train Loss: 0.2845, Val Loss: 0.9828\n",
            "  Epoch: 30, Train Loss: 0.1248, Val Loss: 0.9978\n",
            "  Early stopping at epoch 32\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.8165, Val Loss: 1.3366\n",
            "  Epoch: 20, Train Loss: 0.2731, Val Loss: 0.9830\n",
            "  Epoch: 30, Train Loss: 0.0985, Val Loss: 0.9676\n",
            "  Epoch: 40, Train Loss: 0.0698, Val Loss: 1.0293\n",
            "  Early stopping at epoch 40\n",
            "  Test Accuracy: 0.7930\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.8926, Val Loss: 1.3697\n",
            "  Epoch: 20, Train Loss: 0.2301, Val Loss: 0.9605\n",
            "  Epoch: 30, Train Loss: 0.1223, Val Loss: 0.9450\n",
            "  Early stopping at epoch 35\n",
            "  Test Accuracy: 0.7870\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.7628, Val Loss: 1.2586\n",
            "  Epoch: 20, Train Loss: 0.2081, Val Loss: 0.9270\n",
            "  Epoch: 30, Train Loss: 0.1160, Val Loss: 0.8934\n",
            "  Early stopping at epoch 34\n",
            "  Test Accuracy: 0.7940\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.8893, Val Loss: 1.4226\n",
            "  Epoch: 20, Train Loss: 0.2555, Val Loss: 0.8849\n",
            "  Early stopping at epoch 29\n",
            "  Test Accuracy: 0.7890\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9592, Val Loss: 1.5034\n",
            "  Epoch: 20, Train Loss: 0.3226, Val Loss: 1.0758\n",
            "  Epoch: 30, Train Loss: 0.1197, Val Loss: 1.0405\n",
            "  Epoch: 40, Train Loss: 0.0833, Val Loss: 1.1273\n",
            "  Early stopping at epoch 47\n",
            "  Test Accuracy: 0.7730\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9244, Val Loss: 1.3264\n",
            "  Epoch: 20, Train Loss: 0.2932, Val Loss: 1.0129\n",
            "  Epoch: 30, Train Loss: 0.1185, Val Loss: 0.9481\n",
            "  Early stopping at epoch 36\n",
            "  Test Accuracy: 0.7910\n",
            "\n",
            "Average Accuracy: 0.7899\n",
            "Variance of Accuracy: 0.0001\n",
            "Number of removed edges: 104, Rewired Accuracy: 78.99%, Percentage Improvement: -0.13%, P-value: 0.5396\n",
            "\n",
            "**********\n",
            "Best Hyperparameter:\n",
            "Number of removed edges: 16\n",
            "Accuracy: 79.44%\n",
            "Improvement: 0.32%\n",
            "P-value: 0.0003\n",
            "**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CiteSeer"
      ],
      "metadata": {
        "id": "7FX4dVk6jSQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "patience = 10\n",
        "\n",
        "# Load the Cora dataset\n",
        "dataset = Planetoid(root='data/Planetoid', name='CiteSeer')\n",
        "data = dataset[0]\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "num_edges_before = G.number_of_edges()\n",
        "\n",
        "# Get the model dimensions\n",
        "input_dim = dataset.num_node_features\n",
        "hidden_dims = 16\n",
        "output_dim = dataset.num_classes\n",
        "\n",
        "# Train and evaluate the baseline model\n",
        "accuracies_baseline = train_evaluate_node(input_dim, hidden_dims, output_dim, data, seeds=seeds, patience=patience)\n",
        "baseline_accuracy = np.mean(accuracies_baseline)\n",
        "print(f\"Baseline Accuracy: {baseline_accuracy:.2%}\")\n",
        "\n",
        "accuracies_rewired_list = []\n",
        "p_values = []\n",
        "\n",
        "total_points = 50\n",
        "max_edges = int(num_edges_before * 0.02)\n",
        "step_size = max_edges // (total_points - 1) # Calculate the step size to evenly distribute the points\n",
        "edge_range = range(0, max_edges + 1, step_size)\n",
        "\n",
        "best_accuracy = baseline_accuracy\n",
        "best_edges_removed = 0\n",
        "best_p_value = 1.0\n",
        "\n",
        "start_time = time.time()\n",
        "rewired_data = data  # Initialize rewired_data with the original data\n",
        "\n",
        "for i, n_edges in enumerate(edge_range):\n",
        "    if i > 0:\n",
        "        # Calculate the number of additional edges to add\n",
        "        additional_edges = n_edges - edge_range[i - 1]\n",
        "\n",
        "        # Add the additional edges to the previously rewired data\n",
        "        rewired_data = remove_edges_with_spectral_smoothing(rewired_data, additional_edges)\n",
        "    else:\n",
        "        # For the first iteration, add all the edges\n",
        "        rewired_data = remove_edges_with_spectral_smoothing(data, n_edges)\n",
        "    # Train and evaluate the model on rewired data\n",
        "    accuracies_rewired = train_evaluate_node(input_dim, hidden_dims, output_dim, rewired_data, seeds=seeds, patience=patience)\n",
        "    rewired_accuracy = np.mean(accuracies_rewired)\n",
        "    accuracies_rewired_list.append(rewired_accuracy)\n",
        "\n",
        "    # Calculate percentage improvement\n",
        "    percentage_improvement = (rewired_accuracy - baseline_accuracy) * 100\n",
        "\n",
        "    # Perform statistical test\n",
        "    _, p_value = stats.ttest_rel(accuracies_rewired, accuracies_baseline)\n",
        "    p_values.append(p_value)\n",
        "\n",
        "    print(f\"Number of removed edges: {n_edges}, Rewired Accuracy: {rewired_accuracy:.2%}, \"\n",
        "          f\"Percentage Improvement: {percentage_improvement:.2f}%, P-value: {p_value:.4f}\")\n",
        "\n",
        "    # Update best hyperparameter if current accuracy is higher\n",
        "    if rewired_accuracy > best_accuracy:\n",
        "        best_accuracy = rewired_accuracy\n",
        "        best_edges_removed = n_edges\n",
        "        best_p_value = p_value\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n**********\")\n",
        "elapsed_time = time.time() - start_time\n",
        "minute, second = divmod(elapsed_time, 60)\n",
        "print(f\"Total Execution time: {minute:.2f} minutes {second:.2f} seconds\")\n",
        "print(f\"Best Hyperparameter:\")\n",
        "print(f\"Number of removed edges: {best_edges_removed}\")\n",
        "print(f\"Accuracy: {best_accuracy:.2%}\")\n",
        "print(f\"Improvement: {best_accuracy - baseline_accuracy:.2%}\")\n",
        "print(f\"P-value: {best_p_value:.4f}\")\n",
        "print(\"**********\")\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(edge_range, [acc * 100 for acc in accuracies_rewired_list], marker='o', label='Rewired')\n",
        "plt.axhline(baseline_accuracy * 100, color='r', linestyle='--', label='Baseline')\n",
        "plt.xlabel('Number of Removed Edges')\n",
        "plt.ylabel('Test Accuracy (%)')\n",
        "plt.title('Test Accuracy vs. Edge Removal')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig('TestAccuracy_vs_EdgeRemoval.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QAVo-xRkjbiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PubMed"
      ],
      "metadata": {
        "id": "SkEelqoAktfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 10\n",
        "\n",
        "# Load the Cora dataset\n",
        "dataset = Planetoid(root='data/Planetoid', name='PubMed')\n",
        "data = dataset[0]\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "num_edges_before = G.number_of_edges()\n",
        "\n",
        "# Get the model dimensions\n",
        "input_dim = dataset.num_node_features\n",
        "hidden_dims = 16\n",
        "output_dim = dataset.num_classes\n",
        "\n",
        "# Train and evaluate the baseline model\n",
        "accuracies_baseline = train_evaluate_node(input_dim, hidden_dims, output_dim, data, seeds=seeds, patience=patience)\n",
        "baseline_accuracy = np.mean(accuracies_baseline)\n",
        "print(f\"Baseline Accuracy: {baseline_accuracy:.2%}\")\n",
        "\n",
        "accuracies_rewired_list = []\n",
        "p_values = []\n",
        "\n",
        "total_points = 10\n",
        "max_edges = int(num_edges_before * 0.005)\n",
        "step_size = max_edges // (total_points - 1) # Calculate the step size to evenly distribute the points\n",
        "edge_range = range(0, max_edges + 1, step_size)\n",
        "\n",
        "best_accuracy = baseline_accuracy\n",
        "best_edges_removed = 0\n",
        "best_p_value = 1.0\n",
        "\n",
        "rewired_data = data  # Initialize rewired_data with the original data\n",
        "\n",
        "for i, n_edges in enumerate(edge_range):\n",
        "    if i > 0:\n",
        "        # Calculate the number of additional edges to add\n",
        "        additional_edges = n_edges - edge_range[i - 1]\n",
        "\n",
        "        # Add the additional edges to the previously rewired data\n",
        "        rewired_data = remove_edges_with_spectral_smoothing(rewired_data, additional_edges)\n",
        "    else:\n",
        "        # For the first iteration, add all the edges\n",
        "        rewired_data = remove_edges_with_spectral_smoothing(data, n_edges)\n",
        "\n",
        "    # Train and evaluate the model on rewired data\n",
        "    accuracies_rewired = train_evaluate_node(input_dim, hidden_dims, output_dim, rewired_data, seeds=seeds, patience=patience)\n",
        "    rewired_accuracy = np.mean(accuracies_rewired)\n",
        "    accuracies_rewired_list.append(rewired_accuracy)\n",
        "\n",
        "    # Calculate percentage improvement\n",
        "    percentage_improvement = (rewired_accuracy - baseline_accuracy) * 100\n",
        "\n",
        "    # Perform statistical test\n",
        "    _, p_value = stats.ttest_rel(accuracies_rewired, accuracies_baseline)\n",
        "    p_values.append(p_value)\n",
        "\n",
        "    print(f\"Number of removed edges: {n_edges}, Rewired Accuracy: {rewired_accuracy:.2%}, \"\n",
        "          f\"Percentage Improvement: {percentage_improvement:.2f}%, P-value: {p_value:.4f}\")\n",
        "\n",
        "    # Update best hyperparameter if current accuracy is higher\n",
        "    if rewired_accuracy > best_accuracy:\n",
        "        best_accuracy = rewired_accuracy\n",
        "        best_edges_removed = n_edges\n",
        "        best_p_value = p_value\n",
        "\n",
        "print(\"\\n**********\")\n",
        "print(f\"Best Hyperparameter:\")\n",
        "print(f\"Number of removed edges: {best_edges_removed}\")\n",
        "print(f\"Accuracy: {best_accuracy:.2%}\")\n",
        "print(f\"Improvement: {best_accuracy - baseline_accuracy:.2%}\")\n",
        "print(f\"P-value: {best_p_value:.4f}\")\n",
        "print(\"**********\")\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(edge_range, [acc * 100 for acc in accuracies_rewired_list], marker='o', label='Rewired')\n",
        "plt.axhline(baseline_accuracy * 100, color='r', linestyle='--', label='Baseline')\n",
        "plt.xlabel('Number of Removed Edges')\n",
        "plt.ylabel('Test Accuracy (%)')\n",
        "plt.title('Test Accuracy vs. Edge Removal')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig('TestAccuracy_vs_EdgeRemoval.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CcRrMsK1kw07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewired_data = data  # Initialize rewired_data with the original data\n",
        "\n",
        "n_edges = 200\n",
        "\n",
        "rewired_data = remove_edges_with_spectral_smoothing(data, n_edges)\n",
        "\n",
        "# Train and evaluate the model on rewired data\n",
        "accuracies_rewired = train_evaluate_node(input_dim, hidden_dims, output_dim, rewired_data, seeds=seeds, patience=patience)\n",
        "rewired_accuracy = np.mean(accuracies_rewired)\n",
        "accuracies_rewired_list.append(rewired_accuracy)\n",
        "\n",
        "# Calculate percentage improvement\n",
        "percentage_improvement = (rewired_accuracy - baseline_accuracy) * 100\n",
        "\n",
        "# Perform statistical test\n",
        "_, p_value = stats.ttest_rel(accuracies_rewired, accuracies_baseline)\n",
        "p_values.append(p_value)\n",
        "\n",
        "print(f\"Number of removed edges: {n_edges}, Rewired Accuracy: {rewired_accuracy:.2%}, \"\n",
        "        f\"Percentage Improvement: {percentage_improvement:.2f}%, P-value: {p_value:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COvJ9aNxDvNK",
        "outputId": "42194303-e814-4851-eca7-d62a9a2f386e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of edges removed: 200\n",
            "\n",
            "Seed: 42\n",
            "  Epoch: 10, Train Loss: 0.9613, Val Loss: 1.0206\n",
            "  Epoch: 20, Train Loss: 0.7679, Val Loss: 0.9041\n",
            "  Epoch: 30, Train Loss: 0.5191, Val Loss: 0.7789\n",
            "  Epoch: 40, Train Loss: 0.4021, Val Loss: 0.7080\n",
            "  Epoch: 50, Train Loss: 0.2911, Val Loss: 0.6626\n",
            "  Epoch: 60, Train Loss: 0.2147, Val Loss: 0.6358\n",
            "  Epoch: 70, Train Loss: 0.2217, Val Loss: 0.6110\n",
            "  Epoch: 80, Train Loss: 0.1549, Val Loss: 0.6483\n",
            "  Epoch: 90, Train Loss: 0.1385, Val Loss: 0.6463\n",
            "  Early stopping at epoch 92\n",
            "  Test Accuracy: 0.7790\n",
            "\n",
            "Seed: 220\n",
            "  Epoch: 10, Train Loss: 0.9174, Val Loss: 1.0111\n",
            "  Epoch: 20, Train Loss: 0.6799, Val Loss: 0.8635\n",
            "  Epoch: 30, Train Loss: 0.4895, Val Loss: 0.7536\n",
            "  Epoch: 40, Train Loss: 0.3196, Val Loss: 0.6935\n",
            "  Epoch: 50, Train Loss: 0.2704, Val Loss: 0.6320\n",
            "  Epoch: 60, Train Loss: 0.1596, Val Loss: 0.6345\n",
            "  Epoch: 70, Train Loss: 0.1798, Val Loss: 0.6413\n",
            "  Epoch: 80, Train Loss: 0.1698, Val Loss: 0.6237\n",
            "  Epoch: 90, Train Loss: 0.1507, Val Loss: 0.6264\n",
            "  Early stopping at epoch 94\n",
            "  Test Accuracy: 0.7870\n",
            "\n",
            "Seed: 123\n",
            "  Epoch: 10, Train Loss: 0.9317, Val Loss: 1.0018\n",
            "  Epoch: 20, Train Loss: 0.6962, Val Loss: 0.8678\n",
            "  Epoch: 30, Train Loss: 0.5464, Val Loss: 0.7419\n",
            "  Epoch: 40, Train Loss: 0.3422, Val Loss: 0.6872\n",
            "  Epoch: 50, Train Loss: 0.2558, Val Loss: 0.6486\n",
            "  Early stopping at epoch 55\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 456\n",
            "  Epoch: 10, Train Loss: 0.9540, Val Loss: 1.0043\n",
            "  Epoch: 20, Train Loss: 0.7445, Val Loss: 0.8805\n",
            "  Epoch: 30, Train Loss: 0.5521, Val Loss: 0.7650\n",
            "  Epoch: 40, Train Loss: 0.3953, Val Loss: 0.6933\n",
            "  Epoch: 50, Train Loss: 0.2708, Val Loss: 0.6605\n",
            "  Epoch: 60, Train Loss: 0.2521, Val Loss: 0.6482\n",
            "  Epoch: 70, Train Loss: 0.2040, Val Loss: 0.6620\n",
            "  Early stopping at epoch 76\n",
            "  Test Accuracy: 0.7830\n",
            "\n",
            "Seed: 789\n",
            "  Epoch: 10, Train Loss: 0.9256, Val Loss: 0.9952\n",
            "  Epoch: 20, Train Loss: 0.6248, Val Loss: 0.8580\n",
            "  Epoch: 30, Train Loss: 0.5064, Val Loss: 0.7457\n",
            "  Epoch: 40, Train Loss: 0.3217, Val Loss: 0.6882\n",
            "  Epoch: 50, Train Loss: 0.2674, Val Loss: 0.6763\n",
            "  Epoch: 60, Train Loss: 0.2141, Val Loss: 0.6445\n",
            "  Epoch: 70, Train Loss: 0.1485, Val Loss: 0.6305\n",
            "  Epoch: 80, Train Loss: 0.1468, Val Loss: 0.6357\n",
            "  Early stopping at epoch 81\n",
            "  Test Accuracy: 0.7810\n",
            "\n",
            "Seed: 1011\n",
            "  Epoch: 10, Train Loss: 0.9354, Val Loss: 1.0007\n",
            "  Epoch: 20, Train Loss: 0.6888, Val Loss: 0.8647\n",
            "  Epoch: 30, Train Loss: 0.5042, Val Loss: 0.7638\n",
            "  Epoch: 40, Train Loss: 0.3617, Val Loss: 0.6884\n",
            "  Epoch: 50, Train Loss: 0.2903, Val Loss: 0.6721\n",
            "  Epoch: 60, Train Loss: 0.2067, Val Loss: 0.6420\n",
            "  Epoch: 70, Train Loss: 0.1568, Val Loss: 0.6339\n",
            "  Epoch: 80, Train Loss: 0.1649, Val Loss: 0.6270\n",
            "  Early stopping at epoch 87\n",
            "  Test Accuracy: 0.7820\n",
            "\n",
            "Seed: 1699\n",
            "  Epoch: 10, Train Loss: 0.9578, Val Loss: 1.0198\n",
            "  Epoch: 20, Train Loss: 0.7459, Val Loss: 0.8964\n",
            "  Epoch: 30, Train Loss: 0.5401, Val Loss: 0.7853\n",
            "  Epoch: 40, Train Loss: 0.3838, Val Loss: 0.7176\n",
            "  Epoch: 50, Train Loss: 0.2412, Val Loss: 0.6867\n",
            "  Epoch: 60, Train Loss: 0.2033, Val Loss: 0.6449\n",
            "  Epoch: 70, Train Loss: 0.1768, Val Loss: 0.6536\n",
            "  Early stopping at epoch 73\n",
            "  Test Accuracy: 0.7810\n",
            "\n",
            "Seed: 38994\n",
            "  Epoch: 10, Train Loss: 0.9675, Val Loss: 1.0300\n",
            "  Epoch: 20, Train Loss: 0.7310, Val Loss: 0.8942\n",
            "  Epoch: 30, Train Loss: 0.5162, Val Loss: 0.7761\n",
            "  Epoch: 40, Train Loss: 0.3177, Val Loss: 0.6800\n",
            "  Epoch: 50, Train Loss: 0.2640, Val Loss: 0.6552\n",
            "  Epoch: 60, Train Loss: 0.1902, Val Loss: 0.6287\n",
            "  Epoch: 70, Train Loss: 0.1676, Val Loss: 0.6232\n",
            "  Early stopping at epoch 72\n",
            "  Test Accuracy: 0.7760\n",
            "\n",
            "Seed: 52139\n",
            "  Epoch: 10, Train Loss: 0.9526, Val Loss: 1.0089\n",
            "  Epoch: 20, Train Loss: 0.7605, Val Loss: 0.8885\n",
            "  Epoch: 30, Train Loss: 0.5249, Val Loss: 0.7829\n",
            "  Epoch: 40, Train Loss: 0.3812, Val Loss: 0.7101\n",
            "  Epoch: 50, Train Loss: 0.3195, Val Loss: 0.6750\n",
            "  Epoch: 60, Train Loss: 0.2156, Val Loss: 0.6445\n",
            "  Epoch: 70, Train Loss: 0.1812, Val Loss: 0.6187\n",
            "  Early stopping at epoch 78\n",
            "  Test Accuracy: 0.7770\n",
            "\n",
            "Seed: 123456\n",
            "  Epoch: 10, Train Loss: 0.9367, Val Loss: 0.9978\n",
            "  Epoch: 20, Train Loss: 0.6964, Val Loss: 0.8529\n",
            "  Epoch: 30, Train Loss: 0.4685, Val Loss: 0.7333\n",
            "  Epoch: 40, Train Loss: 0.3051, Val Loss: 0.6657\n",
            "  Epoch: 50, Train Loss: 0.2189, Val Loss: 0.6313\n",
            "  Epoch: 60, Train Loss: 0.1892, Val Loss: 0.6319\n",
            "  Early stopping at epoch 62\n",
            "  Test Accuracy: 0.7780\n",
            "\n",
            "Average Accuracy: 0.7807\n",
            "Variance of Accuracy: 0.0000\n",
            "Number of removed edges: 200, Rewired Accuracy: 78.07%, Percentage Improvement: 0.15%, P-value: 0.0860\n"
          ]
        }
      ]
    }
  ]
}